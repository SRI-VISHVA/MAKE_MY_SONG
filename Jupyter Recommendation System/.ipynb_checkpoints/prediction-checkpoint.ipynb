{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owner</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User</td>\n",
       "      <td>1u8c2t2Cy7UBoG4ArRcF5g</td>\n",
       "      <td>Blank Space</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.703</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.412</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.570</td>\n",
       "      <td>95.997</td>\n",
       "      <td>231827</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User</td>\n",
       "      <td>4iJyoBOLtHqaGxP12qzhQI</td>\n",
       "      <td>Peaches (feat. Daniel Caesar &amp; Giveon)</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.181</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.464</td>\n",
       "      <td>90.030</td>\n",
       "      <td>198082</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User</td>\n",
       "      <td>3TcL0dyCMyr0kyTTc4NLgI</td>\n",
       "      <td>Who Says</td>\n",
       "      <td>Selena Gomez &amp; The Scene</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.927</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.915</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.744</td>\n",
       "      <td>101.019</td>\n",
       "      <td>195613</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>User</td>\n",
       "      <td>3ZFTkvIE7kyPt6Nu3PEa7V</td>\n",
       "      <td>Hips Don't Lie (feat. Wyclef Jean)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.824</td>\n",
       "      <td>10</td>\n",
       "      <td>-5.892</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>0.756</td>\n",
       "      <td>100.024</td>\n",
       "      <td>218093</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  owner                      id                                    name  \\\n",
       "0  User  1u8c2t2Cy7UBoG4ArRcF5g                             Blank Space   \n",
       "1  User  4iJyoBOLtHqaGxP12qzhQI  Peaches (feat. Daniel Caesar & Giveon)   \n",
       "2  User  3TcL0dyCMyr0kyTTc4NLgI                                Who Says   \n",
       "3  User  3ZFTkvIE7kyPt6Nu3PEa7V      Hips Don't Lie (feat. Wyclef Jean)   \n",
       "\n",
       "                    artists  danceability  energy  key  loudness  mode  \\\n",
       "0              Taylor Swift         0.760   0.703    5    -5.412     1   \n",
       "1             Justin Bieber         0.677   0.696    0    -6.181     1   \n",
       "2  Selena Gomez & The Scene         0.682   0.927    4    -2.915     1   \n",
       "3                   Shakira         0.778   0.824   10    -5.892     0   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0       0.0540        0.1030                 0    0.0913    0.570   95.997   \n",
       "1       0.1190        0.3210                 0    0.4200    0.464   90.030   \n",
       "2       0.0479        0.0843                 0    0.1490    0.744  101.019   \n",
       "3       0.0712        0.2840                 0    0.4050    0.756  100.024   \n",
       "\n",
       "   duration_ms  time_signature  ratings  \n",
       "0       231827               4       10  \n",
       "1       198082               4       10  \n",
       "2       195613               4        9  \n",
       "3       218093               4        8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "playlist_df = pd.read_csv(\"playlist.csv\")\n",
    "playlist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = playlist_df.drop(['id','owner','name','artists','ratings'], axis=1)\n",
    "y_train = playlist_df['ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "pca = decomposition.PCA().fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=8 must be between 0 and min(n_samples, n_features)=4 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2ff252b17bdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\virtualenv\\musicviz_final\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mC\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m \u001b[1;34m'np.ascontiguousarray'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \"\"\"\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m         \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\virtualenv\\musicviz_final\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'full'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'arpack'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'randomized'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\virtualenv\\musicviz_final\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[1;34m(self, X, n_components)\u001b[0m\n\u001b[0;32m    447\u001b[0m                              \u001b[1;34m\"min(n_samples, n_features)=%r with \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                              \u001b[1;34m\"svd_solver='full'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                              % (n_components, min(n_samples, n_features)))\n\u001b[0m\u001b[0;32m    450\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mn_components\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: n_components=8 must be between 0 and min(n_samples, n_features)=4 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "pca = decomposition.PCA(n_components=8)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_names = playlist_df['name']\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer(sublinear_tf = True, ngram_range=(1,6),max_features=10000)\n",
    "X_names_sparse=v.fit_transform(track_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "X_train_last = csr_matrix(hstack([X_pca, X_names_sparse]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "skf = StratifiedKFold(n_splits=2,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_params = {'n_neighbors':range(1,4)}\n",
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "knn_grid= GridSearchCV(knn,knn_params,cv=skf,n_jobs =-1,verbose=True)\n",
    "knn_grid.fit(X_train_last,y_train)\n",
    "knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree= DecisionTreeClassifier()\n",
    "\n",
    "tree_params = {'max_depth':range(1,11),'max_features':range(4,19)}\n",
    "tree_grid = GridSearchCV(tree,tree_params,cv=skf,n_jobs=-1,verbose=True)\n",
    "tree_grid.fit(X_train_last,y_train)\n",
    "tree_grid.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = pd.read_csv(\"test3.csv\")\n",
    "rec_playlist_df = test_file.drop(['ratings','id'],axis=1)\n",
    "#rec_playlist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_track_names = test_file['id']\n",
    "tree_grid.best_estimator_.fit(X_train_last,y_train)\n",
    "rec_playlist_df_scaled = StandardScaler().fit_transform(rec_playlist_df)\n",
    "X_test_pca  = pca.transform(rec_playlist_df_scaled)\n",
    "X_test_names = v.transform(rec_track_names)\n",
    "X_test_last = csr_matrix(hstack([X_test_pca,X_test_names]))\n",
    "y_pred_class = tree_grid.best_estimator_.predict(X_test_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_playlist_df['ratings']=y_pred_class\n",
    "rec_playlist_df = rec_playlist_df.sort_values('ratings',ascending=False)\n",
    "rec_playlist_df = rec_playlist_df.reset_index()\n",
    "recs_to_add = rec_playlist_df[rec_playlist_df['ratings']>9]['index'].values.tolist()\n",
    "print(recs_to_add)\n",
    "for i in range(0,len(recs_to_add)):\n",
    "    recs_to_add[i]=recs_to_add[i]+1\n",
    "print(recs_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rec_playlist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "count = 0\n",
    "f = open(\"songs.txt\", \"w\")\n",
    "from csv import reader\n",
    "with open('test3.csv', 'r') as read_obj:\n",
    "    csv_reader = reader(read_obj)\n",
    "    for row in csv_reader:\n",
    "        x=recs_to_add.index(count) if count in recs_to_add else -1\n",
    "        if(x!=-1):\n",
    "            f.write(row[14]+',')\n",
    "        count+=1\n",
    "        \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "User = playlist_df[playlist_df['owner']=='User']\n",
    "\n",
    "\n",
    "user_numeric = playlist_df.drop(['id','owner','name','artists','ratings'], axis=1)\n",
    "user_small = user_numeric.drop(['tempo','duration_ms','key','loudness','time_signature'], axis=1)\n",
    "\n",
    "user_means = pd.DataFrame(user_small.mean(axis=0)).T\n",
    "user_means['owner'] = 'User'\n",
    "\n",
    "means = user_means.append(user_means)\n",
    "means.head()\n",
    "\n",
    "#create a palette from hex codes and set palette\n",
    "bright=[\"#F8766D\",\"#00BFC4\",\"#FFC400\",\"#03ED3A\",\"#003FFF\",\"#8A2BE2\"]\n",
    "sns.set_palette(bright)\n",
    "\n",
    "new = means.melt('owner', var_name='cols',  value_name='vals')\n",
    "sns.catplot(x=\"cols\", y=\"vals\", hue='owner', data=new, kind='bar', height=10, legend_out=False)\n",
    "plt.xticks(rotation = 90, fontsize = 12) #set audio feature labels\n",
    "\n",
    "#set figure size\n",
    "sns.set(rc={'figure.figsize':(20,13)})\n",
    "\n",
    "#Danceability\n",
    "plt.subplot(421)\n",
    "sns.distplot(User['danceability'], color='r')\n",
    "plt.xlabel('DANCEABILITY', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "#Energy\n",
    "plt.subplot(422)\n",
    "sns.distplot(User['energy'], color='r')\n",
    "plt.xlabel('ENERGY', fontsize=13)\n",
    "plt.legend(fontsize=13)\n",
    "\n",
    "#Mode\n",
    "plt.subplot(423)\n",
    "sns.distplot(User['mode'], color='r')\n",
    "plt.xlabel('MODE', fontsize=13)\n",
    "plt.legend(fontsize=13)\n",
    "\n",
    "#Speechiness\n",
    "plt.subplot(424)\n",
    "sns.distplot(User['speechiness'], color='r')\n",
    "plt.xlabel('SPEECHINESS', fontsize=13)\n",
    "plt.legend(fontsize=13)\n",
    "\n",
    "#Acousticness\n",
    "plt.subplot(425)\n",
    "sns.distplot(User['acousticness'], color='r')\n",
    "plt.xlabel('ACOUSTICNESS', fontsize=13)\n",
    "plt.legend(fontsize=13)\n",
    "\n",
    "#Instrumentalness\n",
    "plt.subplot(426)\n",
    "sns.distplot(User['instrumentalness'], color='r').set(ylim=(0, 10))\n",
    "plt.xlabel('INSTRUMENTALNESS', fontsize=13)\n",
    "plt.legend(fontsize=13)\n",
    "\n",
    "#Liveness\n",
    "plt.subplot(427)\n",
    "sns.distplot(User['liveness'], color='r')\n",
    "plt.xlabel('LIVENESS', fontsize=13)\n",
    "plt.legend(fontsize=13)\n",
    "\n",
    "#Valence\n",
    "plt.subplot(428)\n",
    "sns.distplot(User['valence'], color='r')\n",
    "plt.xlabel('VALENCE', fontsize=13)\n",
    "plt.legend(fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list1 = [\"artists\"]\n",
    "df1 = pd.read_csv(\"playlist.csv\", usecols=col_list1)\n",
    "df1[\"artists\"] = df1[\"artists\"].str.replace(' ', '_')\n",
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(width = 1000, height = 600, max_font_size = 200, max_words = 150,\n",
    "                      background_color='white').generate(\" \".join(df1[\"artists\"] ))\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [\"name\"]\n",
    "df = pd.read_csv(\"test2.csv\", usecols=col_list)\n",
    "df[\"name\"] = df[\"name\"].str.replace(' ', '_')\n",
    "wordcloud = WordCloud(width = 1000, height = 600, max_font_size = 200, max_words = 150,\n",
    "                      background_color='white').generate(\" \".join(df[\"name\"]))\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= test_file.loc[test_file['key'] == 1]\n",
    "df11 = test_file.loc[test_file['key'] == 11]\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.jointplot(x=df1['tempo'].values, y=df1['energy'].values, height=10,kind=\"kde\")\n",
    "plt.ylabel('Energy', fontsize=12)\n",
    "plt.xlabel(\"Tempo\", fontsize=12)\n",
    "plt.title(\"Energy Vs Tempo for key=1 \", fontsize=15)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.jointplot(x=df11['tempo'].values, y=df11['energy'].values, height=10, kind=\"kde\")\n",
    "plt.ylabel('Energy', fontsize=12)\n",
    "plt.xlabel(\"Tempo\", fontsize=12)\n",
    "plt.title(\"Energy Vs Tempo for key=11\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y=\"danceability\", x=\"mode\", kind=\"boxen\", data=playlist_df)\n",
    "sns.catplot(y=\"liveness\", x=\"mode\", kind=\"boxen\", data=playlist_df)\n",
    "sns.catplot(y=\"valence\", x=\"mode\", kind=\"boxen\", data=playlist_df)\n",
    "sns.catplot(y=\"energy\", x=\"mode\", kind=\"boxen\", data=playlist_df)\n",
    "sns.catplot(y=\"loudness\", x=\"mode\", kind=\"boxen\", data=playlist_df)\n",
    "sns.catplot(y=\"speechiness\", x=\"mode\", kind=\"boxen\", data=playlist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
